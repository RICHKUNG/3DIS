"""
Semantic-SAM å½±åƒåˆ†å‰²è™•ç†ç®¡ç·šï¼ˆç²¾ç°¡ç‰ˆ CLIï¼‰
ç”¨æ–¼ç”ŸæˆæŒ‡å®šå±¤ç´šçš„èªç¾©åˆ†å‰²é®ç½©ï¼Œä¸¦çµ±ä¸€è¼¸å‡ºçµæ§‹

Author: Rich Kung
Updated: 2025-09-09
"""

# =====================
# å¥—ä»¶åŒ¯å…¥
# =====================
import os
import sys
import datetime
import time
import numpy as np
from PIL import Image
from tqdm import tqdm
import json
import argparse  # optional, kept for future use
import csv
import subprocess

DEFAULT_SEMANTIC_SAM_ROOT = os.environ.get(
    "SEMANTIC_SAM_ROOT",
    "/media/Pluto/richkung/Semantic-SAM",
)

if DEFAULT_SEMANTIC_SAM_ROOT and DEFAULT_SEMANTIC_SAM_ROOT not in sys.path:
    sys.path.append(DEFAULT_SEMANTIC_SAM_ROOT)

from semantic_sam import (
    prepare_image,
    plot_results,
    build_semantic_sam,
    SemanticSamAutomaticMaskGenerator,
)

# åŒ¯å…¥ auto_generation_inference.py çš„å¾Œè™•ç†å‡½å¼
from auto_generation_inference import (
    instance_map_to_anns,
)

# =====================
# åƒæ•¸è¨­å®š
# =====================
MODEL_TYPE = "L"  # ä½¿ç”¨ SwinL æ¨¡å‹
CKPT_PATH = os.path.join(
    DEFAULT_SEMANTIC_SAM_ROOT,
    "checkpoints",
    "swinl_only_sam_many2many.pth",
)
# é è¨­è¼¸å‡ºåˆ°å°ˆæ¡ˆå…§çµ±ä¸€è³‡æ–™å¤¾ï¼ˆå¯ç”± CLI è¦†è“‹ï¼‰
OUTPUT_ROOT = os.path.join(os.path.dirname(__file__), "exp_outputs", "progressive_refinement")

# æ–°å¢ï¼šæª”æ¡ˆå‘½åè¦ç¯„è¨­å®š
EXPERIMENT_NAME = "experiment"
USE_TIMESTAMP = True
VERBOSE = False  # æ§åˆ¶è©³ç´°è¼¸å‡ºï¼Œé è¨­é—œé–‰ä»¥é™ä½çµ‚ç«¯è¼¸å‡º
SAVE_VIZ = True  # é è¨­ä¸è¼¸å‡ºå¤§é‡ parent/child è¦–è¦ºåŒ–


def console(message, *, important=False):
    """é›†ä¸­æ§åˆ¶éé—œéµè¼¸å‡ºçš„é¡¯ç¤ºè¡Œç‚º"""
    if important or VERBOSE:
        print(message)

# =====================
# å¯¦é©—è¨­å®šï¼ˆé›†ä¸­æ–¼æ­¤ç·¨è¼¯å³å¯ï¼‰
# =====================
SCENE_NAME = "scene_00065_00"
DATA_ROOT = "/media/public_dataset2/multiscan/"
LEVELS = [2, 4, 6]          # å¿…é ˆéå¢ï¼Œä¸”è‡³å°‘å…©å€‹å±¤ç´š
RANGE_STR = "1400:1500:20"  # start:end:stepï¼ˆend ç‚ºæ’ä»–ï¼‰
MIN_AREA = 200
MAX_MASKS = 2000
NO_TIMESTAMP = False        # True æ™‚ä¸åŠ æ™‚é–“æˆ³è¨˜

# é¡å¤–åŒ¯å…¥ï¼ˆç”¨æ–¼é¿å…åè¦†å­˜æª”è®€æª”ï¼‰
try:
    import torch
    from torchvision import transforms
    from torchvision.transforms import InterpolationMode
except Exception:
    torch = None
    transforms = None
    InterpolationMode = None

# =====================
# å·¥å…·å‡½æ•¸
# =====================
def timer_decorator(func):
    """è¨ˆæ™‚è£é£¾å™¨"""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        duration = end_time - start_time
        
        func_name = func.__name__.replace('_', ' ').title()
        if duration < 60:
            print(f"â±ï¸  {func_name} å®Œæˆï¼Œè€—æ™‚: {duration:.2f} ç§’")
        else:
            minutes = int(duration // 60)
            seconds = duration % 60
            print(f"â±ï¸  {func_name} å®Œæˆï¼Œè€—æ™‚: {minutes}åˆ†{seconds:.1f}ç§’")
        
        return result
    return wrapper

def log_step(step_name, start_time=None):
    """è¨˜éŒ„æ­¥é©Ÿé€²åº¦"""
    if start_time:
        duration = time.time() - start_time
        if duration < 60:
            print(f"âœ… {step_name} - è€—æ™‚: {duration:.2f}ç§’")
        else:
            minutes = int(duration // 60)
            seconds = duration % 60
            print(f"âœ… {step_name} - è€—æ™‚: {minutes}åˆ†{seconds:.1f}ç§’")
    else:
        print(f"ğŸ”„ é–‹å§‹: {step_name}")


def parse_levels(levels_str):
    """å°‡ '2,4,6' è§£æç‚º [2,4,6]"""
    if isinstance(levels_str, (list, tuple)):
        return [int(x) for x in levels_str]
    return [int(x) for x in str(levels_str).split(',') if str(x).strip()]


def parse_range(range_str):
    """å°‡ 'start:end:step' è§£æç‚ºä¸‰å…ƒçµ„"""
    parts = str(range_str).split(':')
    if len(parts) != 3:
        raise ValueError("range éœ€ç‚º 'start:end:step' æ ¼å¼ï¼Œä¾‹å¦‚ 1400:1700:20")
    return int(parts[0]), int(parts[1]), int(parts[2])


def get_git_commit_hash(default=None):
    try:
        out = subprocess.check_output(["git", "rev-parse", "HEAD"], cwd=os.path.dirname(__file__))
        return out.decode("utf-8").strip()
    except Exception:
        return default


def instance_map_to_color_image(instance_map):
    """å°‡ instance_map è½‰ç‚ºå½©è‰²åœ–ï¼ˆåˆ©æ–¼å¿«é€Ÿç¸½è¦½ï¼‰"""
    h, w = instance_map.shape
    colored = np.zeros((h, w, 3), dtype=np.uint8)
    ids = np.unique(instance_map)
    rng = np.random.default_rng(0)
    color_map = {0: (0, 0, 0)}
    for uid in ids:
        if uid == 0:
            continue
        color_map[int(uid)] = tuple(rng.integers(0, 255, size=3).tolist())
    for uid, color in color_map.items():
        colored[instance_map == uid] = color
    return Image.fromarray(colored, 'RGB')


def bbox_from_mask(seg):
    ys, xs = np.where(seg)
    if len(xs) == 0:
        return None
    return int(xs.min()), int(ys.min()), int(xs.max()), int(ys.max())

# =====================
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸
# =====================
def get_experiment_timestamp():
    """ç”Ÿæˆå¯¦é©—æ™‚é–“æˆ³è¨˜"""
    return datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

def create_experiment_folder(base_path, experiment_name, timestamp=None):
    """å»ºç«‹å¸¶æ™‚é–“æˆ³è¨˜çš„å¯¦é©—è³‡æ–™å¤¾"""
    if timestamp is None:
        timestamp = get_experiment_timestamp()
    
    experiment_folder = f"{experiment_name}_{timestamp}"
    full_path = os.path.join(base_path, experiment_folder)
    os.makedirs(full_path, exist_ok=True)
    
    return full_path, timestamp

def setup_output_directories(experiment_path):
    """å»ºç«‹è¼¸å‡ºç›®éŒ„çµæ§‹ï¼ˆç²¾ç°¡çµ±ä¸€ï¼‰
    experiment_path/
      original/
      levels/level_{L}/
      relations/
      summary/
      viz/ (å¯é¸)
    """
    dirs = [
        "original",
        "levels",
        "relations",
        "summary",
        "viz",
    ]
    created_dirs = {}
    for d in dirs:
        p = os.path.join(experiment_path, d)
        os.makedirs(p, exist_ok=True)
        created_dirs[d] = p
    return created_dirs

@timer_decorator
def save_original_image_info(image_path, output_dirs):
    """å„²å­˜åŸå§‹åœ–ç‰‡"""
    try:
        original_dir = output_dirs["original"]
        
        # è¤‡è£½åŸå§‹åœ–ç‰‡åˆ°è¼¸å‡ºç›®éŒ„
        import shutil
        original_filename = os.path.basename(image_path)
        copied_path = os.path.join(original_dir, f"original_{original_filename}")
        shutil.copy2(image_path, copied_path)
        
        return {"original_path": image_path, "copied_path": copied_path}
    except Exception as e:
        console(f"âŒ å„²å­˜åŸå§‹åœ–ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", important=True)
        return None


def prepare_image_from_pil(pil_img):
    """ä»¿ç…§ semantic_sam.prepare_imageï¼Œä½†æ¥å— PIL ç‰©ä»¶ï¼Œé¿å…è½åœ°å­˜æª”å†è®€å–ã€‚
    å›å‚³ (image_ori_np, torch_tensor_on_cuda)
    """
    if transforms is None or torch is None:
        # å¾Œå‚™ï¼šè½åœ°å­˜æª”ï¼ˆè¼ƒæ…¢ï¼Œç›¡é‡é¿å…ï¼‰
        tmp_path = os.path.join("/tmp", f"masked_{int(time.time()*1000)}.png")
        try:
            pil_img.save(tmp_path)
            return prepare_image(image_pth=tmp_path)
        finally:
            try:
                if os.path.exists(tmp_path):
                    os.remove(tmp_path)
            except Exception:
                pass

    if pil_img.mode != 'RGB':
        pil_img = pil_img.convert('RGB')
    resize_interpolation = InterpolationMode.BICUBIC if InterpolationMode else Image.BICUBIC
    transform1 = transforms.Resize(640, interpolation=resize_interpolation)
    image_resized = transform1(pil_img)
    image_ori = np.asarray(image_resized)
    images = torch.from_numpy(image_ori.copy()).permute(2, 0, 1).cuda()
    return image_ori, images

def create_masked_image(original_image, mask_data, background_color=(0, 0, 0)):
    """
    å‰µå»ºè¢« mask çš„åœ–ç‰‡ï¼Œmask å¤–çš„å€åŸŸè¨­ç‚ºæŒ‡å®šèƒŒæ™¯è‰²
    
    Args:
        original_image: PIL Image åŸå§‹åœ–ç‰‡
        mask_data: numpy array mask æ•¸æ“š (True/False æˆ– 0/255)
        background_color: èƒŒæ™¯å¡«å……é¡è‰² (R, G, B)
        
    Returns:
        PIL Image: è¢« mask çš„åœ–ç‰‡
    """
    try:
        # ç¢ºä¿è¼¸å…¥åœ–ç‰‡æ˜¯ PIL Image ä¸”ç‚º RGB æ¨¡å¼
        if not isinstance(original_image, Image.Image):
            raise ValueError("è¼¸å…¥å¿…é ˆæ˜¯ PIL Image")
        
        if original_image.mode != 'RGB':
            original_image = original_image.convert('RGB')
        
        # å°‡åœ–ç‰‡è½‰ç‚º numpy array
        img_array = np.array(original_image)
        result_array = img_array.copy()
        
        # è™•ç† mask æ•¸æ“š
        if isinstance(mask_data, np.ndarray):
            # æ¨™æº–åŒ– mask ç‚º boolean
            if mask_data.dtype == bool:
                mask_binary = mask_data
            elif mask_data.dtype == np.uint8:
                mask_binary = mask_data > 0
            else:
                mask_binary = mask_data > 0.5
            
            # ç¢ºä¿ mask æ˜¯ 2D
            if len(mask_binary.shape) > 2:
                mask_binary = mask_binary.squeeze()
                if len(mask_binary.shape) > 2:
                    mask_binary = mask_binary[:, :, 0]
            
            # èª¿æ•´ mask å°ºå¯¸ä»¥åŒ¹é…åœ–ç‰‡
            if mask_binary.shape != img_array.shape[:2]:
                mask_pil = Image.fromarray((mask_binary * 255).astype(np.uint8), 'L')
                mask_pil = mask_pil.resize(original_image.size, Image.NEAREST)
                mask_binary = np.array(mask_pil) > 127
            
            # å°‡ mask å¤–çš„å€åŸŸè¨­ç‚ºèƒŒæ™¯è‰²
            mask_inverse = ~mask_binary
            for c in range(3):  # RGB é€šé“
                result_array[mask_inverse, c] = background_color[c]
            
            return Image.fromarray(result_array, 'RGB')
        else:
            if VERBOSE:
                console(f"è­¦å‘Šï¼šmask æ•¸æ“šæ ¼å¼ä¸æ­£ç¢º: {type(mask_data)}")
            return original_image
            
    except Exception as e:
        if VERBOSE:
            console(f"å‰µå»º masked åœ–ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return original_image

@timer_decorator
def progressive_refinement_masks(semantic_sam, image_path, level_sequence, output_dirs, min_area=50, max_masks_per_level=200, save_viz=False):
    """
    åŸ·è¡Œæ¼¸é€²å¼ç´°åŒ– mask ç”Ÿæˆï¼Œä¸¦ä»¥æœ‰åºæ–¹å¼å„²å­˜çµæœ
    """
    main_start = time.time()
    log_step(f"æ¼¸é€²å¼ç´°åŒ–è™•ç† (Levels: {level_sequence})")
    
    # é©—è­‰ level åºåˆ—
    if not level_sequence or len(level_sequence) < 2:
        raise ValueError("level_sequence å¿…é ˆåŒ…å«è‡³å°‘ 2 å€‹ level")
    
    if level_sequence != sorted(level_sequence):
        raise ValueError("level_sequence å¿…é ˆæ˜¯éå¢åºåˆ—")
    
    # è¼‰å…¥åŸå§‹åœ–ç‰‡
    original_image_pil, input_image = prepare_image(image_pth=image_path)
    
    # ç¢ºä¿ original_image_pil æ˜¯ PIL Image æ ¼å¼
    if not isinstance(original_image_pil, Image.Image):
        if isinstance(original_image_pil, np.ndarray):
            # è½‰æ› numpy array ç‚º PIL Image
            if len(original_image_pil.shape) == 3:
                if original_image_pil.shape[2] == 3:  # RGB
                    if original_image_pil.dtype != np.uint8:
                        original_image_pil = (original_image_pil * 255).astype(np.uint8)
                    original_image_pil = Image.fromarray(original_image_pil, 'RGB')
                elif original_image_pil.shape[2] == 4:  # RGBA
                    if original_image_pil.dtype != np.uint8:
                        original_image_pil = (original_image_pil * 255).astype(np.uint8)
                    original_image_pil = Image.fromarray(original_image_pil, 'RGBA').convert('RGB')
            elif len(original_image_pil.shape) == 2:  # ç°éš
                if original_image_pil.dtype != np.uint8:
                    original_image_pil = (original_image_pil * 255).astype(np.uint8)
                original_image_pil = Image.fromarray(original_image_pil, 'L').convert('RGB')
            console(f"å·²å°‡ numpy array è½‰æ›ç‚º PIL Image: {original_image_pil.size}")
        else:
            raise TypeError(f"ä¸æ”¯æ´çš„åœ–ç‰‡æ ¼å¼: {type(original_image_pil)}")
    
    # ç¢ºä¿æ˜¯ RGB æ¨¡å¼
    if original_image_pil.mode != 'RGB':
        original_image_pil = original_image_pil.convert('RGB')
    
    console(f"åŸå§‹åœ–ç‰‡æ ¼å¼ç¢ºèª: {type(original_image_pil)}, æ¨¡å¼: {original_image_pil.mode}, å°ºå¯¸: {original_image_pil.size}")
    
    # è¨­å®šç›®éŒ„
    sequence_str = "_".join(map(str, level_sequence))
    parent_child_dir = os.path.join(output_dirs["viz"], f"sequence_{sequence_str}")
    levels_root = os.path.join(output_dirs["levels"], f"sequence_{sequence_str}")
    os.makedirs(levels_root, exist_ok=True)
    if save_viz:
        os.makedirs(parent_child_dir, exist_ok=True)
    
    # åªä¿ç•™å¿…è¦çš„çµæœè®Šæ•¸
    refinement_results = {
        'level_sequence': level_sequence,
        'levels': {}
    }
    tree_relations = {}  # æ¯å±¤çš„ç¯€é»åˆ—è¡¨
    id_to_node = {}      # å…¨åŸŸå”¯ä¸€ id å°æ‡‰ node
    mask_id_counter = 1  # å…¨åŸŸå”¯ä¸€ id
    all_nodes = []       # æ–°å¢ï¼šæ”¶é›†æ‰€æœ‰ç¯€é»

    # ç¬¬ä¸€å€‹ levelï¼šåœ¨åŸåœ–ä¸Šç”Ÿæˆ mask
    first_level = level_sequence[0]
    console(f"\nğŸ¯ Level {first_level} (åŸåœ–)")

    mask_generator = SemanticSamAutomaticMaskGenerator(semantic_sam, level=[first_level])
    first_level_masks = mask_generator.generate(input_image)

    # === åˆä½µç‚º instance mapï¼Œæ‹†å› mask listï¼Œç¢ºä¿åŒå±¤ä¸é‡ç–Š ===
    height, width = original_image_pil.size[1], original_image_pil.size[0]
    instance_map = np.zeros((height, width), dtype=np.int32)
    for idx, mask in enumerate(first_level_masks):
        if 'segmentation' in mask:
            seg = mask['segmentation']
            instance_map[(seg) & (instance_map == 0)] = idx + 1  # idå¾1é–‹å§‹
    first_level_masks = instance_map_to_anns(instance_map)

    # å…ˆä¸å„²å­˜ï¼Œå¾… unique_id æŒ‡æ´¾å¾Œç”¨ unique_id é‡æ–°å»ºåœ–å†å­˜

    # === å”¯ä¸€ id èˆ‡æ¨¹ç‹€çµæ§‹ ===
    tree_relations[first_level] = []
    # ç¬¬ä¸€å±¤
    for mask in first_level_masks:
        node = {
            "id": mask_id_counter,
            "parent": None,
            "children": []
        }
        tree_relations[first_level].append(node)
        id_to_node[mask_id_counter] = node
        all_nodes.append(node)  # æ”¶é›†
        mask['unique_id'] = mask_id_counter
        mask_id_counter += 1

    # éæ¿¾å’Œé™åˆ¶ mask æ•¸é‡
    first_level_masks = [m for m in first_level_masks if m.get('area', 0) >= min_area]
    if len(first_level_masks) > max_masks_per_level:
        first_level_masks = first_level_masks[:max_masks_per_level]

    console(f"âœ¨ Level {first_level}: {len(first_level_masks)} å€‹æœ‰æ•ˆ mask")
    
    # ä½¿ç”¨ unique_id å»ºç«‹ instance_map ä¸¦å„²å­˜
    level_dir = os.path.join(levels_root, f"level_{first_level}")
    os.makedirs(level_dir, exist_ok=True)
    instance_map_unique = np.zeros((height, width), dtype=np.int32)
    for m in first_level_masks:
        if 'segmentation' in m:
            seg = m['segmentation']
            instance_map_unique[(seg) & (instance_map_unique == 0)] = m['unique_id']
    np.save(os.path.join(level_dir, "instance_map.npy"), instance_map_unique)
    try:
        instance_img = instance_map_to_color_image(instance_map_unique)
        instance_img.save(os.path.join(level_dir, "colored_instances.png"))
    except Exception:
        pass

    # å„²å­˜ç¬¬ä¸€å€‹ level çš„è¦–è¦ºåŒ–çµæœï¼ˆåŸç”Ÿå‡½å¼ï¼‰
    plot_results(first_level_masks, original_image_pil, save_path=level_dir)
        
    refinement_results['levels'][first_level] = {
        'masks': first_level_masks,
        'mask_count': len(first_level_masks),
    }

    # ç•¶å‰è™•ç†çš„ mask åˆ—è¡¨ï¼ˆç”¨æ–¼ä¸‹ä¸€å€‹ level çš„è¼¸å…¥ï¼‰
    current_masks = first_level_masks
    current_level = first_level
    
    # è™•ç†å¾ŒçºŒçš„ level
    level_pbar = tqdm(level_sequence[1:], desc="æ¼¸é€²ç´°åŒ–", bar_format='{l_bar}{bar:20}{r_bar}')
    
    for next_level in level_pbar:
        level_start = time.time()
        level_pbar.set_description(f"Level {current_level}â†’{next_level}")
        
        next_level_all_masks = []
        next_level_parent_info = []
        
        # ç‚ºæœ¬å±¤å»ºç«‹ parent-child é—œä¿‚ç›®éŒ„
        # æ›´ç›´è§€çš„éšå±¤è³‡æ–™å¤¾å‘½åï¼šL{cur}_to_L{next}
        parent_child_level_dir = os.path.join(parent_child_dir, f"L{current_level}_to_L{next_level}")
        if save_viz:
            os.makedirs(parent_child_level_dir, exist_ok=True)
        
        # ç‚ºæ¯å€‹ç•¶å‰ level çš„ mask ç”Ÿæˆæ›´ç´°çš„ mask
        parent_pbar = tqdm(enumerate(current_masks), total=len(current_masks), 
                          desc="è™•ç† parent masks", leave=False,
                          bar_format='{l_bar}{bar:15}{r_bar}{postfix}')
        
        successful_parents = 0
        total_children = 0
        
        for parent_idx, parent_mask in parent_pbar:
            try:
                # ç²å– parent mask çš„ segmentation æ•¸æ“š
                if 'segmentation' not in parent_mask:
                    next_level_parent_info.append({
                        'parent_id': parent_idx,
                        'child_count': 0,
                        'error': 'no_segmentation'
                    })
                    continue
                
                parent_seg = parent_mask['segmentation']
                
                # å‰µå»ºè¢« mask çš„åœ–ç‰‡ï¼ˆmask å¤–ç‚ºé»‘è‰²ï¼‰
                masked_image = create_masked_image(original_image_pil, parent_seg, background_color=(0, 0, 0))
                
                # ç¢ºä¿ masked_image æ˜¯ PIL Image
                if not isinstance(masked_image, Image.Image):
                    next_level_parent_info.append({
                        'parent_id': parent_idx,
                        'child_count': 0,
                        'error': 'masked_image_format_error'
                    })
                    continue
                
                # å¯é¸å„²å­˜ masked åœ–ç‰‡
                if save_viz:
                    try:
                        parent_uid = current_masks[parent_idx]['unique_id']
                        parent_dir = os.path.join(parent_child_level_dir, f"P{parent_uid}")
                        os.makedirs(parent_dir, exist_ok=True)
                        masked_img_path = os.path.join(parent_dir, f"parent_L{current_level}_P{parent_uid}.png")
                        masked_image.save(masked_img_path)
                    except Exception as save_error:
                        if VERBOSE:
                            console(f"å„²å­˜ masked åœ–ç‰‡å¤±æ•—: {str(save_error)}")

                # ç›´æ¥å°‡ masked PIL è½‰æ›ç‚ºæ¨¡å‹è¼¸å…¥æ ¼å¼ï¼ˆé¿å…å…ˆè½åœ°ï¼‰
                try:
                    _, masked_input = prepare_image_from_pil(masked_image)
                except Exception as _:
                    next_level_parent_info.append({
                        'parent_id': parent_idx,
                        'child_count': 0,
                        'error': 'prepare_image_failed'
                    })
                    continue
                
                # åœ¨ masked åœ–ç‰‡ä¸Šç”Ÿæˆä¸‹ä¸€å€‹ level çš„ mask
                try:
                    mask_generator = SemanticSamAutomaticMaskGenerator(semantic_sam, level=[next_level])
                    child_masks = mask_generator.generate(masked_input)
                    # ğŸ”¥ child segmentation èˆ‡ parent segmentation åš AND
                    for child_mask in child_masks:
                        if 'segmentation' in child_mask:
                            child_mask['segmentation'] = np.logical_and(child_mask['segmentation'], parent_seg)
                    # ğŸ”¥ åªä¿ç•™é¢ç©å¤§æ–¼ min_area ä¸” segmentation ä¸ç­‰æ–¼ parent_seg çš„ child mask
                    def mask_iou(mask1, mask2):
                        inter = np.logical_and(mask1, mask2).sum()
                        union = np.logical_or(mask1, mask2).sum()
                        return inter / union if union > 0 else 0.0
                    similarity_threshold = 0.95
                    child_masks = [
                        m for m in child_masks
                        if np.sum(m['segmentation']) >= min_area and mask_iou(m['segmentation'], parent_seg) < similarity_threshold
                    ]
                except Exception as _:
                    next_level_parent_info.append({
                        'parent_id': parent_idx,
                        'child_count': 0,
                        'error': 'mask_generation_failed'
                    })
                    continue
                
                # éæ¿¾æœ‰æ•ˆçš„ child mask
                valid_child_masks = []
                if save_viz:
                    parent_uid = current_masks[parent_idx]['unique_id']
                    child_dir = os.path.join(parent_child_level_dir, f"P{parent_uid}")
                    os.makedirs(child_dir, exist_ok=True)

                for child_idx, child_mask in enumerate(child_masks):
                    if child_mask.get('area', 0) >= min_area:
                        # æ·»åŠ  parent è³‡è¨Š
                        child_mask['parent_mask_id'] = parent_idx
                        child_mask['parent_level'] = current_level
                        child_mask['current_level'] = next_level
                        # åˆ†é…å”¯ä¸€ id
                        child_mask['unique_id'] = mask_id_counter
                        valid_child_masks.append(child_mask)
                        # å»ºç«‹ parent-child é—œè¯
                        parent_unique_id = current_masks[parent_idx]['unique_id']
                        mask_id_counter += 1
                        # å¦‚æœæœ‰åˆ†å‰²è³‡è¨Šï¼Œå„²å­˜ child mask çš„è¦–è¦ºåŒ–
                        if save_viz and 'segmentation' in child_mask:
                            try:
                                child_mask_img = create_masked_image(original_image_pil, child_mask['segmentation'], background_color=(0, 0, 0))
                                parent_uid = current_masks[parent_idx]['unique_id']
                                child_uid = child_mask.get('unique_id', mask_id_counter)
                                child_img_path = os.path.join(child_dir, f"child_L{next_level}_C{child_uid}_from_P{parent_uid}.png")
                                child_mask_img.save(child_img_path)
                            except Exception as save_error:
                                if VERBOSE:
                                    console(f"å„²å­˜ child åœ–ç‰‡å¤±æ•—: {str(save_error)}")

                # å¦‚æœæˆåŠŸç”Ÿæˆäº† child masksï¼Œå­˜å„²è¦ªå­é—œä¿‚åœ–ç‰‡ï¼ˆç§»åˆ°é€™è£¡ï¼‰
                if save_viz and valid_child_masks:
                    try:
                        parent_uid = current_masks[parent_idx]['unique_id']
                        parent_img_path = os.path.join(child_dir, f"parent_L{current_level}_P{parent_uid}.png")
                        masked_image.save(parent_img_path)
                    except Exception:
                        pass

                next_level_all_masks.extend(valid_child_masks)
                next_level_parent_info.append({
                    'parent_id': parent_idx,
                    'child_count': len(valid_child_masks),
                    'error': None
                })
                
                if len(valid_child_masks) > 0:
                    successful_parents += 1
                    total_children += len(valid_child_masks)
                
                # è¨˜éŒ„parentèˆ‡childå°æ‡‰
                
                # æ›´æ–°é€²åº¦æ¢
                avg_children = total_children / successful_parents if successful_parents > 0 else 0
                parent_pbar.set_postfix({
                    "æˆåŠŸ": successful_parents,
                    "å¹³å‡å­æ•¸": f"{avg_children:.1f}"
                })
                
            except Exception as e:
                next_level_parent_info.append({
                    'parent_id': parent_idx,
                    'child_count': 0,
                    'error': str(e)
                })
                continue
        
        parent_pbar.close()

        # åˆä½µæ‰€æœ‰ child mask ç‚º instance mapï¼Œæ‹†å› mask list
        if next_level_all_masks:
            height, width = original_image_pil.size[1], original_image_pil.size[0]
            instance_map = np.zeros((height, width), dtype=np.int32)
            for idx, mask in enumerate(next_level_all_masks):
                if 'segmentation' in mask:
                    seg = mask['segmentation']
                    instance_map[(seg) & (instance_map == 0)] = idx + 1
            # instance_map_to_anns ç”¢ç”Ÿçš„æ–° mask éœ€é‡æ–°åˆ†é…å”¯ä¸€ id èˆ‡ parent
            new_masks = instance_map_to_anns(instance_map)
            new_mask_list = []
            for idx, mask in enumerate(new_masks):
                # å˜—è©¦æ‰¾å‡ºä¾†æº parent
                # é€™è£¡ç”¨æœ€é‡ç–Šçš„åŸå§‹ child mask ä¾†æ±ºå®š parent
                max_iou = 0
                parent_unique_id = None
                for orig_mask in next_level_all_masks:
                    inter = np.logical_and(mask['segmentation'], orig_mask['segmentation']).sum()
                    union = np.logical_or(mask['segmentation'], orig_mask['segmentation']).sum()
                    iou = inter / union if union > 0 else 0
                    if iou > max_iou:
                        max_iou = iou
                        parent_unique_id = orig_mask.get('parent_mask_id', None)
                        parent_unique_id = orig_mask.get('parent_unique_id', orig_mask.get('parent_mask_id', None))
                        # é€™è£¡ parent_unique_id å…¶å¯¦æ‡‰è©²æ˜¯ parent çš„ unique_id
                        if 'parent_unique_id' in orig_mask:
                            parent_unique_id = orig_mask['parent_unique_id']
                        else:
                            # å¾ current_masks å–å¾—
                            if orig_mask.get('parent_mask_id') is not None and orig_mask['parent_mask_id'] < len(current_masks):
                                parent_unique_id = current_masks[orig_mask['parent_mask_id']]['unique_id']
                # è‹¥æ‰¾ä¸åˆ°ï¼Œé è¨­æŒ‡æ´¾åˆ°ä¸Šä¸€å±¤ç¬¬ä¸€å€‹
                if parent_unique_id is None and len(current_masks) > 0:
                    parent_unique_id = current_masks[0]['unique_id']
                # åˆ†é…å”¯ä¸€ id
                mask['unique_id'] = mask_id_counter
                mask['parent_unique_id'] = parent_unique_id
                # å»ºç«‹ parent-child é—œè¯
                mask_id_counter += 1
                new_mask_list.append(mask)
            next_level_all_masks = new_mask_list
            for m in next_level_all_masks:
                m['current_level'] = next_level

        # ä½¿ç”¨ unique_id é‡æ–°å»ºç«‹ instance_map ä¸¦å„²å­˜ï¼ˆé¿å…é‡è¤‡ä¸”æ›´ç›´è§€ï¼‰
        next_level_dir = os.path.join(levels_root, f"level_{next_level}")
        os.makedirs(next_level_dir, exist_ok=True)
        instance_map_unique = np.zeros((height, width), dtype=np.int32)
        for m in next_level_all_masks:
            if 'segmentation' in m:
                seg = m['segmentation']
                instance_map_unique[(seg) & (instance_map_unique == 0)] = m['unique_id']
        np.save(os.path.join(next_level_dir, "instance_map.npy"), instance_map_unique)
        try:
            instance_img = instance_map_to_color_image(instance_map_unique)
            instance_img.save(os.path.join(next_level_dir, "colored_instances.png"))
        except Exception:
            pass

        # å»ºç«‹æœ¬å±¤æ¨¹ç‹€é—œä¿‚
        tree_relations[next_level] = []
        for mask in next_level_all_masks:
            node = {
                "id": mask['unique_id'],
                "parent": mask.get('parent_unique_id', None),
                "children": []
            }
            tree_relations[next_level].append(node)
            id_to_node[node["id"]] = node
            all_nodes.append(node)  # æ”¶é›†

        # è£œå…… parent çš„ children
        for node in tree_relations[next_level]:
            pid = node["parent"]
            if pid is not None and pid in id_to_node:
                # é¿å…é‡è¤‡åŠ å…¥
                if node["id"] not in id_to_node[pid]["children"]:
                    id_to_node[pid]["children"].append(node["id"])

        # å–®å±¤æ¨¹ç‹€é—œä¿‚ï¼ˆJSONï¼‰
        with open(os.path.join(next_level_dir, "tree.json"), "w", encoding="utf-8") as f:
            json.dump(tree_relations[next_level], f, ensure_ascii=False, indent=2)

        refinement_results['levels'][next_level] = {
            'masks': next_level_all_masks,
            'mask_count': len(next_level_all_masks),
        }

        current_masks = next_level_all_masks
        current_level = next_level
        # é¡¯ç¤ºæœ¬å±¤çµ±è¨ˆ
        level_duration = time.time() - level_start
        console(
            f"âœ¨ Level {next_level}: {len(next_level_all_masks)} å€‹ mask "
            f"(ä¾†è‡ª {successful_parents}/{len(next_level_parent_info)} å€‹ parentï¼Œ"
            f"è€—æ™‚ {level_duration:.1f}ç§’)",
            important=True,
        )
    
    level_pbar.close()

    # å„²å­˜ç¬¬ä¸€å±¤æ¨¹ç‹€é—œä¿‚ JSON
    first_level_dir = os.path.join(levels_root, f"level_{first_level}")
    with open(os.path.join(first_level_dir, "tree.json"), "w", encoding="utf-8") as f:
        json.dump(tree_relations[first_level], f, ensure_ascii=False, indent=2)

    # å„²å­˜å…¨åŸŸæ¨¹ç‹€é—œä¿‚ JSONï¼ˆçµ±ä¸€æ”¾ relations/ï¼‰
    relations_dir = output_dirs["relations"]
    with open(os.path.join(relations_dir, "tree.json"), "w", encoding="utf-8") as f:
        json.dump(tree_relations, f, ensure_ascii=False, indent=2)

    # ç”¢å‡ºç°¡æ˜“é—œä¿‚è¡¨ï¼ˆrelations.csvï¼‰ï¼šid,parent,level,area,bbox
    csv_path = os.path.join(relations_dir, "relations.csv")
    with open(csv_path, "w", newline="", encoding="utf-8") as cf:
        writer = csv.writer(cf)
        writer.writerow(["id", "parent", "level", "area", "bbox"])  # bbox: x_min,y_min,x_max,y_max
        for level, nodes in tree_relations.items():
            # å¾ refinement_results å– area èˆ‡ bbox
            masks = refinement_results['levels'].get(level, {}).get('masks', [])
            # å»ºç«‹ id -> mask å°æ‡‰
            id2mask = {m.get('unique_id'): m for m in masks}
            for node in nodes:
                m = id2mask.get(node['id'])
                area = int(m.get('area', 0)) if m else 0
                bbox = None
                if m and 'segmentation' in m:
                    b = bbox_from_mask(m['segmentation'])
                    bbox = b if b else None
                writer.writerow([
                    node['id'], node['parent'], level, area,
                    ("%d,%d,%d,%d" % bbox) if bbox else ""
                ])

    log_step("æ¼¸é€²å¼ç´°åŒ–è™•ç†å®Œæˆ", main_start)
    return refinement_results


# =====================
# ä¸»è¦åŸ·è¡Œæµç¨‹
# =====================
@timer_decorator
def main():
    """ä¸»è¦åŸ·è¡Œæµç¨‹ï¼ˆè¨­å®šé›†ä¸­æ–¼æª”æ¡ˆå…§ï¼‰"""
    console("ğŸš€ å•Ÿå‹• Semantic-SAM å½±åƒåˆ†å‰²è™•ç†ç®¡ç·š", important=True)
    # è¨­å®šå·¥ä½œç›®éŒ„åˆ° Semantic-SAM è³‡æ–™å¤¾
    script_dir = os.path.dirname(os.path.abspath(__file__))
    os.chdir(script_dir)
    console(f"ğŸ“ å·¥ä½œç›®éŒ„: {os.getcwd()}")

    # åˆå§‹åŒ–æ¨¡å‹
    console("ğŸ”§ æ­£åœ¨è¼‰å…¥ Semantic-SAM æ¨¡å‹...")
    model_start = time.time()
    try:
        semantic_sam = build_semantic_sam(model_type=MODEL_TYPE, ckpt=CKPT_PATH)
        model_time = time.time() - model_start
        console(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼è€—æ™‚: {model_time:.2f}ç§’", important=True)
    except Exception as e:
        console(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}", important=True)
        return

    # å»ºç«‹å¯¦é©—è³‡æ–™å¤¾
    setup_start = time.time()
    os.makedirs(OUTPUT_ROOT, exist_ok=True)
    experiment_path, ts = create_experiment_folder(
        OUTPUT_ROOT,
        EXPERIMENT_NAME,
        timestamp=get_experiment_timestamp() if (USE_TIMESTAMP and not NO_TIMESTAMP) else None
    )
    console(f"ğŸ“‚ å¯¦é©—è³‡æ–™å¤¾: {experiment_path}")
    image_index_csv = os.path.join(experiment_path, 'summary', 'index.csv')

    # è¨­å®šè¼¸å‡ºç›®éŒ„
    _ = setup_output_directories(experiment_path)
    setup_time = time.time() - setup_start
    console(f"âœ… ç›®éŒ„è¨­ç½®å®Œæˆï¼Œè€—æ™‚: {setup_time:.2f}ç§’", important=True)

    # Manifestï¼ˆæé«˜å¯é‡ç¾æ€§ï¼‰
    manifest = {
        "timestamp": ts,
        "scene": SCENE_NAME,
        "levels": LEVELS,
        "range": RANGE_STR,
        "min_area": MIN_AREA,
        "max_masks": MAX_MASKS,
        "model_type": MODEL_TYPE,
        "ckpt": CKPT_PATH,
        "git_commit": get_git_commit_hash(),
        "save_viz": bool(SAVE_VIZ),
    }
    with open(os.path.join(experiment_path, 'summary', 'manifest.json'), 'w', encoding='utf-8') as f:
        json.dump(manifest, f, ensure_ascii=False, indent=2)

    # å¤šå¼µåœ–ç‰‡è™•ç†
    data_folder_source = os.path.join(DATA_ROOT, SCENE_NAME, "outputs", "color")
    all_color_images = sorted(os.listdir(data_folder_source))
    start_idx, end_idx, frequency = parse_range(RANGE_STR)
    selected_images = [all_color_images[i] for i in range(start_idx, end_idx, frequency) if 0 <= i < len(all_color_images)]
    console(f"å…±é¸å– {len(selected_images)} å¼µåœ–ç‰‡é€²è¡Œå¯¦é©—")

    # æº–å‚™ index å½™æ•´
    if not os.path.exists(image_index_csv):
        with open(image_index_csv, 'w', newline='', encoding='utf-8') as cf:
            writer = csv.writer(cf)
            writer.writerow(["image", "image_path", "total_masks", "levels", "output_dir"])

    for idx, selected_image in enumerate(selected_images):
        image_path = os.path.join(data_folder_source, selected_image)
        image_stem = os.path.splitext(selected_image)[0]
        console(f"\n=== è™•ç†ç¬¬ {idx+1} å¼µ: {image_path} ===")
        # ç‚ºæ¯å¼µåœ–ç‰‡å»ºç«‹ç¨ç«‹çš„ output è³‡æ–™å¤¾
        image_output_root = os.path.join(experiment_path, image_stem)
        os.makedirs(image_output_root, exist_ok=True)
        image_output_dirs = setup_output_directories(image_output_root)
        try:
            # å„²å­˜åŸå§‹åœ–ç‰‡
            save_original_image_info(image_path, image_output_dirs)

            # æ¼¸é€²å¼ç´°åŒ–
            console("\nğŸ¯ åŸ·è¡Œæ¼¸é€²å¼ç´°åŒ–")
            level_seq = LEVELS
            refinement_results = progressive_refinement_masks(
                semantic_sam,
                image_path,
                level_sequence=level_seq,
                output_dirs=image_output_dirs,
                min_area=MIN_AREA,
                max_masks_per_level=MAX_MASKS,
                save_viz=bool(SAVE_VIZ)
            )

            # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ + è¼¸å‡º metrics.json
            console("\nğŸ“Š === æœ€çµ‚çµæœçµ±è¨ˆ ===", important=True)
            total_masks = 0
            metrics = {"levels": {}, "total_masks": 0}
            for level, data in refinement_results['levels'].items():
                mask_count = data['mask_count']
                total_masks += mask_count
                metrics["levels"][str(level)] = {"mask_count": mask_count}
                console(f"Level {level}: {mask_count:4d} å€‹ mask", important=True)
            metrics["total_masks"] = total_masks
            with open(os.path.join(image_output_root, 'summary', 'metrics.json'), 'w', encoding='utf-8') as f:
                json.dump(metrics, f, ensure_ascii=False, indent=2)

            # æ›´æ–° index.csv
            with open(image_index_csv, 'a', newline='', encoding='utf-8') as cf:
                writer = csv.writer(cf)
                writer.writerow([image_stem, image_path, total_masks, ",".join(map(str, level_seq)), image_output_root])

            console(f"\nğŸ‰ ç¸½è¨ˆç”Ÿæˆ: {total_masks} å€‹ mask", important=True)
            console(f"\nâœ… å¯¦é©—å®Œæˆï¼æ‰€æœ‰çµæœå·²å„²å­˜åˆ°: {image_output_root}", important=True)

        except FileNotFoundError:
            console(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°åœ–ç‰‡æª”æ¡ˆ {image_path}", important=True)
            console("è«‹æª¢æŸ¥åœ–ç‰‡è·¯å¾‘æ˜¯å¦æ­£ç¢º", important=True)
        except Exception as e:
            console(f"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}", important=True)
            if VERBOSE:
                import traceback
                traceback.print_exc()

if __name__ == "__main__":
    main()
